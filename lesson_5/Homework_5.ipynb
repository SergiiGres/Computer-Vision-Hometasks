{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floyd-Steinberg Dithering\n",
    "\n",
    "In this homework you are going to implement the Floy-Steinberg dithering algorithm. Dithering, in general, means that we are adding noise to the signal (in our case digital image) in order to perceive it better. In other words, by adding the noise the objective quality will be worse but the subjective quality will be better (i.e. the image will \"look\" better).\n",
    "\n",
    "The details of FS dithering can be found in this [wiki](https://en.wikipedia.org/wiki/Floyd%E2%80%93Steinberg_dithering) page. In order to implement the dithering, we will implement the following steps:\n",
    "* Define colour pallette\n",
    "* Quantize the image to obtain the baseline and compute the average quantization error\n",
    "* Implement FS dithering and compute the average quantization error\n",
    "\n",
    "As always, you are encouraged to use your own images :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load image\n",
    "img = cv2.imread('...')\n",
    "# Convert it to RGB\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# Plot it\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with gray tones first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Black, dark gray, light gray, white\n",
    "colors = np.array([[0, 0, 0],\n",
    "                   [64, 64, 64],\n",
    "                   [192, 192, 192],\n",
    "                   [255, 255, 255]])\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=16).fit(np.reshape(img, (-1, 3)))\n",
    "colors = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the colour pallette, let's quantize the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cast the image to float\n",
    "img = img.astype(np.float32)\n",
    "rows, cols, channels = img.shape\n",
    "quantized = np.zeros_like(img)\n",
    "\n",
    "# Apply quantization\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "        # Extract the original pixel value\n",
    "        pixel = img[r, c, :]\n",
    "        # Find the closest colour from the pallette (using absolute value/Euclidean distance)\n",
    "        # Note: You may need more than one line of code here        \n",
    "        diff = colors - pixel\n",
    "        diff = np.sum(np.abs(diff), axis=1)\n",
    "        quantized[r, c, :] = colors[np.argmin(diff), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show quantized image (don't forget to cast back to uint8)\n",
    "plt.imshow(quantized.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute average quantization error\n",
    "mse = np.mean((img - quantized)**2)\n",
    "print('PSNR', 10*np.log10(255**2/mse), 'dB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Floyd-Steinberg Dithering\n",
    "We are now going to implement the FS dithering and compare it to the optimally quantized image we have calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a temporal copy of the original image, we will need it for error diffusion\n",
    "img_tmp = np.copy(img)\n",
    "dithering = np.zeros_like(img)\n",
    "\n",
    "for r in range(1, rows-1):\n",
    "    for c in range(1, cols-1):\n",
    "        # Extract the original pixel value\n",
    "        pixel = img_tmp[r, c, :]\n",
    "        # Find the closest colour from the pallette (using absolute value/Euclidean distance)\n",
    "        # Note: You may need more than one line of code here        \n",
    "        diff = colors - pixel        \n",
    "        diff = np.sum(np.abs(diff), axis=1)\n",
    "        new_pixel = colors[np.argmin(diff), :]\n",
    "        \n",
    "        # Compute quantization error\n",
    "        quant_error = pixel - new_pixel\n",
    "        \n",
    "        # Diffuse the quantization error accroding to the FS diffusion matrix\n",
    "        # Note: You may need more than one line of code here\n",
    "        img_tmp[r, c+1] = img_tmp[r, c+1] + 7/16 * quant_error\n",
    "        img_tmp[r+1, c-1] = img_tmp[r+1, c-1] + 3/16 * quant_error\n",
    "        img_tmp[r+1, c] = img_tmp[r+1, c] + 5/16 * quant_error\n",
    "        img_tmp[r+1, c+1] = img_tmp[r+1, c+1] + 1/16 * quant_error        \n",
    "        \n",
    "        # Apply dithering\n",
    "        dithering[r, c] = new_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show quantized image (don't forget to cast back to uint8)\n",
    "plt.subplot(121), plt.imshow(quantized.astype(np.uint8))\n",
    "plt.subplot(122), plt.imshow(dithering.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute average quantization error\n",
    "mse = np.mean((img - dithering)**2)\n",
    "print('PSNR', 10*np.log10(255**2/mse), 'dB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* Which image has higher quantization error? Optimally quantized or dithered?\n",
    "* Which image looks better to you?\n",
    "* Can you repeat the same process using only two colours: black and white? Show me :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Points\n",
    "\n",
    "Repeat the homework using a diffrerent image pallette. For instance, you can use an optimal colour\n",
    "pallette that we can calculate via k-means algorithm. The following snippet of code will give you the 16\n",
    "optimal colours for your original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=16).fit(np.reshape(img, (-1, 3)))\n",
    "colors = kmeans.cluster_centers_\n",
    "print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply FS dithering the same way you did before.\n",
    "* How does the result look like to you?\n",
    "* What happens if we use 32 colours?\n",
    "* And what happens if we use 256 colours?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}